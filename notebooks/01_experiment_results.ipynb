{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# 01. Experiment Results Analysis\n",
    "\n",
    "이 노트북은 레이어 선택 실험 결과를 분석하고 시각화합니다.\n",
    "\n",
    "## 목차\n",
    "1. 환경 설정 및 데이터 로딩\n",
    "2. Q1: Last Layer가 최적인가?\n",
    "3. Q3: Heuristic 성능 비교\n",
    "4. Layer-Performance Curves\n",
    "5. 논문용 Figure 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-header",
   "metadata": {},
   "source": [
    "## 1. 환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "# 논문용 스타일 설정\n",
    "plt.rcParams.update({\n",
    "    'font.size': 11,\n",
    "    'axes.labelsize': 12,\n",
    "    'axes.titlesize': 13,\n",
    "    'xtick.labelsize': 10,\n",
    "    'ytick.labelsize': 10,\n",
    "    'legend.fontsize': 10,\n",
    "    'figure.titlesize': 14,\n",
    "    'figure.dpi': 150,\n",
    "    'savefig.dpi': 300,\n",
    "    'savefig.bbox': 'tight',\n",
    "    'font.family': 'sans-serif',\n",
    "})\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# 프로젝트 루트 설정\n",
    "PROJECT_ROOT = Path(\"..\")\n",
    "RESULTS_DIR = PROJECT_ROOT / \"results\"\n",
    "FIGURES_DIR = Path(\"figures\")\n",
    "FIGURES_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"Project root: {PROJECT_ROOT.resolve()}\")\n",
    "print(f\"Results dir: {RESULTS_DIR.resolve()}\")\n",
    "print(f\"Figures dir: {FIGURES_DIR.resolve()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "config-header",
   "metadata": {},
   "source": [
    "### 1.1 실험 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "config",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실험 설정\n",
    "DATASETS = {\n",
    "    \"classification\": [\"sst2\", \"cola\", \"imdb\", \"tweet_offensive\", \"tweet_sentiment_binary\"],\n",
    "    \"entailment\": [\"snli\", \"mnli\"]\n",
    "}\n",
    "\n",
    "LLM_CONFIGS = {\n",
    "    \"qwen2_0.5b\": {\"name\": \"Qwen2-0.5B\", \"layers\": 24},\n",
    "    \"qwen2_1.5b\": {\"name\": \"Qwen2-1.5B\", \"layers\": 28},\n",
    "    \"qwen2_7b\": {\"name\": \"Qwen2-7B\", \"layers\": 32},\n",
    "}\n",
    "\n",
    "SEEDS = [2023, 2024, 2025]\n",
    "\n",
    "# 색상 팔레트\n",
    "COLORS = {\n",
    "    \"best\": \"#2ecc71\",      # 초록\n",
    "    \"last\": \"#e74c3c\",      # 빨강\n",
    "    \"selected\": \"#f39c12\", # 주황\n",
    "    \"pcl\": \"#3498db\",      # 파랑\n",
    "    \"line\": \"#34495e\",      # 회색\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loaders-header",
   "metadata": {},
   "source": [
    "### 1.2 데이터 로딩 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loaders",
   "metadata": {},
   "outputs": [],
   "source": "def parse_grid_results(path: Path) -> pd.DataFrame:\n    \"\"\"\n    Grid search 결과 파일을 파싱합니다.\n    예상 형식: layer=0 acc=0.85 f1=0.84\n    \"\"\"\n    rows = []\n    if not path.exists():\n        return pd.DataFrame(columns=[\"layer\", \"acc\", \"f1\"])\n    \n    for line in path.read_text().splitlines():\n        line = line.strip()\n        if not line:\n            continue\n        parts = line.split()\n        kv = {}\n        for p in parts:\n            if \"=\" in p:\n                k, v = p.split(\"=\", 1)\n                kv[k] = v\n        if \"layer\" not in kv or \"acc\" not in kv:\n            continue\n        layer = int(kv[\"layer\"])\n        acc = float(kv[\"acc\"])\n        f1 = float(kv.get(\"f1\", kv.get(\"macro_f1\", acc)))\n        rows.append({\"layer\": layer, \"acc\": acc, \"f1\": f1})\n    \n    return pd.DataFrame(rows).sort_values(\"layer\").reset_index(drop=True)\n\n\ndef load_selection_log(task: str, dataset: str, llm_type: str, seed: int = 2023) -> Optional[Dict]:\n    \"\"\"\n    Selection 로그 JSON 파일을 로드합니다.\n    새 로그 포맷: head_effects, per_layer_probe_acc 포함\n    \"\"\"\n    # 여러 가능한 경로 시도\n    possible_paths = [\n        # 새 형식 (auto_select_layer에서 저장)\n        RESULTS_DIR / \"selection_logs\" / f\"{task}_{dataset}_{llm_type}_seed{seed}.json\",\n        RESULTS_DIR / f\"{task}_{dataset}_{llm_type}_seed{seed}.json\",\n        # 기존 형식\n        RESULTS_DIR / \"layer_selection\" / f\"{task}_{dataset}_{llm_type}_seed{seed}.json\",\n        RESULTS_DIR / \"layer_selection\" / task / dataset / \"bert\" / llm_type / \"selection.json\",\n        RESULTS_DIR / f\"{task}_{dataset}_{llm_type}_selection.json\",\n    ]\n    \n    for path in possible_paths:\n        if path.exists():\n            try:\n                return json.loads(path.read_text())\n            except:\n                continue\n    return None\n\n\ndef get_layer_stats(grid_df: pd.DataFrame, sel_log: Optional[Dict] = None) -> Dict:\n    \"\"\"\n    Grid search 결과에서 주요 통계를 계산합니다.\n    \"\"\"\n    if grid_df.empty:\n        return None\n    \n    best_idx = grid_df[\"acc\"].idxmax()\n    best = grid_df.iloc[best_idx]\n    last = grid_df.iloc[grid_df[\"layer\"].idxmax()]\n    \n    stats = {\n        \"best_layer\": int(best[\"layer\"]),\n        \"best_acc\": float(best[\"acc\"]),\n        \"best_f1\": float(best[\"f1\"]),\n        \"last_layer\": int(last[\"layer\"]),\n        \"last_acc\": float(last[\"acc\"]),\n        \"last_f1\": float(last[\"f1\"]),\n        \"best_last_gap\": float(best[\"acc\"] - last[\"acc\"]),\n        \"is_last_optimal\": int(best[\"layer\"]) == int(last[\"layer\"]),\n        \"total_layers\": len(grid_df),\n        \"min_acc\": float(grid_df[\"acc\"].min()),\n        \"max_acc\": float(grid_df[\"acc\"].max()),\n        \"acc_std\": float(grid_df[\"acc\"].std()),\n    }\n    \n    # Sensitivity 계산\n    stats[\"sensitivity\"] = (stats[\"max_acc\"] - stats[\"min_acc\"]) / max(stats[\"max_acc\"], 1e-8)\n    \n    # Selection 로그가 있으면 추가 정보\n    if sel_log:\n        sel_layer = sel_log.get(\"final_layer\", sel_log.get(\"L_Apply\", sel_log.get(\"L_Abstract\", -1)))\n        if sel_layer >= 0 and sel_layer in grid_df[\"layer\"].values:\n            sel_row = grid_df[grid_df[\"layer\"] == sel_layer].iloc[0]\n            stats[\"sel_layer\"] = int(sel_layer)\n            stats[\"sel_acc\"] = float(sel_row[\"acc\"])\n            stats[\"sel_last_gap\"] = float(sel_row[\"acc\"] - last[\"acc\"])\n            stats[\"sel_best_gap\"] = float(sel_row[\"acc\"] - best[\"acc\"])\n            if stats[\"best_last_gap\"] != 0:\n                stats[\"recovery_rate\"] = stats[\"sel_last_gap\"] / stats[\"best_last_gap\"]\n            else:\n                stats[\"recovery_rate\"] = 1.0\n            \n            # 새로 추가된 로그 필드\n            stats[\"L_Abstract\"] = sel_log.get(\"L_Abstract\", -1)\n            stats[\"L_Apply\"] = sel_log.get(\"L_Apply\", -1)\n            stats[\"base_probe_acc\"] = sel_log.get(\"base_acc\")\n            stats[\"max_head_effect\"] = sel_log.get(\"max_head_effect\")\n            \n            # per_layer_probe_acc가 있으면 best layer의 probe acc 추가\n            probe_accs = sel_log.get(\"per_layer_probe_acc\", [])\n            if probe_accs and stats[\"best_layer\"] < len(probe_accs):\n                stats[\"best_layer_probe_acc\"] = probe_accs[stats[\"best_layer\"]]\n    \n    return stats"
  },
  {
   "cell_type": "markdown",
   "id": "collect-header",
   "metadata": {},
   "source": [
    "### 1.3 전체 결과 수집"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collect-results",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_all_results() -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    모든 실험 결과를 수집하여 DataFrame으로 반환합니다.\n",
    "    \"\"\"\n",
    "    all_results = []\n",
    "    \n",
    "    for task, datasets in DATASETS.items():\n",
    "        for dataset in datasets:\n",
    "            for llm_type, llm_info in LLM_CONFIGS.items():\n",
    "                # Grid results 파일 경로 시도\n",
    "                grid_paths = [\n",
    "                    RESULTS_DIR / f\"{dataset}_bert_{llm_type}_results.txt\",\n",
    "                    RESULTS_DIR / task / f\"{dataset}_bert_{llm_type}_results.txt\",\n",
    "                    PROJECT_ROOT / \"Classification\" / \"results\" / f\"{dataset}_bert_{llm_type}_results.txt\",\n",
    "                ]\n",
    "                \n",
    "                grid_df = pd.DataFrame()\n",
    "                for path in grid_paths:\n",
    "                    grid_df = parse_grid_results(path)\n",
    "                    if not grid_df.empty:\n",
    "                        break\n",
    "                \n",
    "                sel_log = load_selection_log(task, dataset, llm_type)\n",
    "                stats = get_layer_stats(grid_df, sel_log)\n",
    "                \n",
    "                if stats:\n",
    "                    stats[\"task\"] = task\n",
    "                    stats[\"dataset\"] = dataset\n",
    "                    stats[\"llm_type\"] = llm_type\n",
    "                    stats[\"llm_name\"] = llm_info[\"name\"]\n",
    "                    all_results.append(stats)\n",
    "    \n",
    "    if not all_results:\n",
    "        print(\"Warning: No results found. Creating synthetic example data for demonstration.\")\n",
    "        return create_synthetic_data()\n",
    "    \n",
    "    return pd.DataFrame(all_results)\n",
    "\n",
    "\n",
    "def create_synthetic_data() -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    실제 결과가 없을 때 시연용 합성 데이터 생성\n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "    results = []\n",
    "    \n",
    "    for task, datasets in DATASETS.items():\n",
    "        for dataset in datasets:\n",
    "            for llm_type, llm_info in LLM_CONFIGS.items():\n",
    "                n_layers = llm_info[\"layers\"]\n",
    "                \n",
    "                # 기본 성능 (태스크별로 다르게)\n",
    "                base_acc = np.random.uniform(0.80, 0.92)\n",
    "                \n",
    "                # 레이어별 성능 변동 (중간 레이어가 최적인 경향)\n",
    "                best_layer = np.random.randint(n_layers // 3, 2 * n_layers // 3)\n",
    "                best_acc = base_acc + np.random.uniform(0.02, 0.05)\n",
    "                last_acc = base_acc + np.random.uniform(-0.02, 0.02)\n",
    "                \n",
    "                # Selection이 best에 가깝게\n",
    "                sel_layer = best_layer + np.random.randint(-2, 3)\n",
    "                sel_layer = max(0, min(sel_layer, n_layers - 1))\n",
    "                sel_acc = best_acc - np.random.uniform(0, 0.01)\n",
    "                \n",
    "                results.append({\n",
    "                    \"task\": task,\n",
    "                    \"dataset\": dataset,\n",
    "                    \"llm_type\": llm_type,\n",
    "                    \"llm_name\": llm_info[\"name\"],\n",
    "                    \"best_layer\": best_layer,\n",
    "                    \"best_acc\": best_acc,\n",
    "                    \"last_layer\": n_layers - 1,\n",
    "                    \"last_acc\": last_acc,\n",
    "                    \"best_last_gap\": best_acc - last_acc,\n",
    "                    \"is_last_optimal\": False,\n",
    "                    \"sel_layer\": sel_layer,\n",
    "                    \"sel_acc\": sel_acc,\n",
    "                    \"sel_last_gap\": sel_acc - last_acc,\n",
    "                    \"sel_best_gap\": sel_acc - best_acc,\n",
    "                    \"recovery_rate\": (sel_acc - last_acc) / max(best_acc - last_acc, 1e-8),\n",
    "                    \"sensitivity\": np.random.uniform(0.05, 0.15),\n",
    "                    \"total_layers\": n_layers,\n",
    "                })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "# 결과 수집\n",
    "results_df = collect_all_results()\n",
    "print(f\"Collected {len(results_df)} experiment configurations\")\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "q1-header",
   "metadata": {},
   "source": [
    "## 2. Q1: Last Layer가 최적인가?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "q1-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1 분석: 마지막 레이어 최적성\n",
    "\n",
    "def analyze_last_layer_optimality(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    마지막 레이어가 최적인 경우의 비율과 gap 통계를 계산합니다.\n",
    "    \"\"\"\n",
    "    summary = []\n",
    "    \n",
    "    # 전체 통계\n",
    "    total = len(df)\n",
    "    optimal_count = df[\"is_last_optimal\"].sum() if \"is_last_optimal\" in df.columns else 0\n",
    "    \n",
    "    summary.append({\n",
    "        \"group\": \"Overall\",\n",
    "        \"n_experiments\": total,\n",
    "        \"last_optimal_count\": optimal_count,\n",
    "        \"last_optimal_pct\": 100 * optimal_count / max(total, 1),\n",
    "        \"avg_best_last_gap\": df[\"best_last_gap\"].mean() if \"best_last_gap\" in df.columns else 0,\n",
    "        \"std_best_last_gap\": df[\"best_last_gap\"].std() if \"best_last_gap\" in df.columns else 0,\n",
    "        \"max_best_last_gap\": df[\"best_last_gap\"].max() if \"best_last_gap\" in df.columns else 0,\n",
    "    })\n",
    "    \n",
    "    # 태스크별 통계\n",
    "    for task in df[\"task\"].unique():\n",
    "        task_df = df[df[\"task\"] == task]\n",
    "        optimal_count = task_df[\"is_last_optimal\"].sum() if \"is_last_optimal\" in task_df.columns else 0\n",
    "        summary.append({\n",
    "            \"group\": f\"Task: {task}\",\n",
    "            \"n_experiments\": len(task_df),\n",
    "            \"last_optimal_count\": optimal_count,\n",
    "            \"last_optimal_pct\": 100 * optimal_count / max(len(task_df), 1),\n",
    "            \"avg_best_last_gap\": task_df[\"best_last_gap\"].mean() if \"best_last_gap\" in task_df.columns else 0,\n",
    "            \"std_best_last_gap\": task_df[\"best_last_gap\"].std() if \"best_last_gap\" in task_df.columns else 0,\n",
    "            \"max_best_last_gap\": task_df[\"best_last_gap\"].max() if \"best_last_gap\" in task_df.columns else 0,\n",
    "        })\n",
    "    \n",
    "    # 데이터셋별 통계\n",
    "    for dataset in df[\"dataset\"].unique():\n",
    "        ds_df = df[df[\"dataset\"] == dataset]\n",
    "        optimal_count = ds_df[\"is_last_optimal\"].sum() if \"is_last_optimal\" in ds_df.columns else 0\n",
    "        summary.append({\n",
    "            \"group\": f\"Dataset: {dataset}\",\n",
    "            \"n_experiments\": len(ds_df),\n",
    "            \"last_optimal_count\": optimal_count,\n",
    "            \"last_optimal_pct\": 100 * optimal_count / max(len(ds_df), 1),\n",
    "            \"avg_best_last_gap\": ds_df[\"best_last_gap\"].mean() if \"best_last_gap\" in ds_df.columns else 0,\n",
    "            \"std_best_last_gap\": ds_df[\"best_last_gap\"].std() if \"best_last_gap\" in ds_df.columns else 0,\n",
    "            \"max_best_last_gap\": ds_df[\"best_last_gap\"].max() if \"best_last_gap\" in ds_df.columns else 0,\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(summary)\n",
    "\n",
    "\n",
    "q1_summary = analyze_last_layer_optimality(results_df)\n",
    "print(\"=\" * 60)\n",
    "print(\"Q1: Is the Last Layer Optimal?\")\n",
    "print(\"=\" * 60)\n",
    "q1_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "q1-visualization",
   "metadata": {},
   "outputs": [],
   "source": "# Q1 시각화: Last Layer Optimality 분석\n\nfig, axes = plt.subplots(1, 3, figsize=(15, 4.5))\n\n# (a) 태스크별 Last=Best 비율\nax1 = axes[0]\nif \"dataset\" in results_df.columns and \"is_last_optimal\" in results_df.columns:\n    # 데이터셋별 last=best 비율 계산\n    optimal_ratio = results_df.groupby(\"dataset\")[\"is_last_optimal\"].mean() * 100\n    optimal_ratio = optimal_ratio.sort_values(ascending=False)\n    \n    colors_bar = [COLORS[\"best\"] if r < 50 else COLORS[\"last\"] for r in optimal_ratio.values]\n    bars = ax1.bar(range(len(optimal_ratio)), optimal_ratio.values, color=colors_bar, \n                   edgecolor=\"black\", alpha=0.7)\n    ax1.set_xticks(range(len(optimal_ratio)))\n    ax1.set_xticklabels(optimal_ratio.index, rotation=45, ha=\"right\")\n    ax1.set_ylabel(\"Last = Best (%)\")\n    ax1.set_xlabel(\"Dataset\")\n    ax1.set_title(\"(a) Last Layer Optimality Rate\")\n    ax1.axhline(y=50, color=\"gray\", linestyle=\"--\", alpha=0.5, label=\"50%\")\n    ax1.set_ylim(0, 100)\n    \n    # 각 바에 값 표시\n    for i, (bar, val) in enumerate(zip(bars, optimal_ratio.values)):\n        ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 2, \n                 f\"{val:.0f}%\", ha=\"center\", va=\"bottom\", fontsize=9)\n\n# (b) Best-Last Gap 분포 (박스플롯)\nax2 = axes[1]\nif \"dataset\" in results_df.columns and \"best_last_gap\" in results_df.columns:\n    order = results_df.groupby(\"dataset\")[\"best_last_gap\"].mean().sort_values(ascending=False).index\n    sns.boxplot(data=results_df, x=\"dataset\", y=\"best_last_gap\", order=order, ax=ax2, palette=\"Set2\")\n    ax2.axhline(y=0, color=\"gray\", linestyle=\"--\", alpha=0.5)\n    ax2.set_xlabel(\"Dataset\")\n    ax2.set_ylabel(\"Best - Last Gap (Accuracy)\")\n    ax2.set_title(\"(b) Performance Gap Distribution\")\n    ax2.tick_params(axis='x', rotation=45)\n\n# (c) 최적 레이어 위치 히스토그램\nax3 = axes[2]\nif \"best_layer\" in results_df.columns and \"total_layers\" in results_df.columns:\n    # 정규화된 레이어 위치 (0-1)\n    results_df[\"best_layer_norm\"] = results_df[\"best_layer\"] / results_df[\"total_layers\"]\n    ax3.hist(results_df[\"best_layer_norm\"], bins=10, edgecolor=\"black\", alpha=0.7, color=COLORS[\"best\"])\n    ax3.axvline(x=1.0, color=COLORS[\"last\"], linestyle=\"--\", linewidth=2, label=\"Last layer\")\n    ax3.set_xlabel(\"Normalized Layer Position (0=first, 1=last)\")\n    ax3.set_ylabel(\"Frequency\")\n    ax3.set_title(\"(c) Optimal Layer Distribution\")\n    ax3.legend()\n\nplt.tight_layout()\nplt.savefig(FIGURES_DIR / \"q1_last_layer_optimal.pdf\")\nplt.savefig(FIGURES_DIR / \"q1_last_layer_optimal.png\")\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "id": "1z36xmzq6pr",
   "source": "### Figure 해석 가이드: Q1 Last Layer Optimality\n\n#### (a) Last Layer Optimality Rate (Bar Chart)\n- **X축**: 데이터셋 이름\n- **Y축**: Last Layer가 최적인 비율 (%)\n- **색상**: 초록 (50% 미만), 빨강 (50% 이상)\n- **해석 방법**:\n  - **낮은 비율 (초록)**: 대부분의 경우 Last layer가 최적이 아님 → 레이어 선택 중요\n  - **높은 비율 (빨강)**: Last layer가 자주 최적 → 레이어 선택 불필요할 수 있음\n  - **50% 점선**: 기준선, 이 아래면 레이어 선택의 가치가 있음\n- **논문 주장**: 전체적으로 비율이 낮으면 \"last layer가 항상 최적은 아니다\" 지지\n\n#### (b) Performance Gap Distribution (Box Plot)\n- **X축**: 데이터셋 이름\n- **Y축**: Best Layer Accuracy - Last Layer Accuracy (차이값)\n- **해석 방법**:\n  - **양수 값**: Best layer가 Last layer보다 좋음 → 레이어 선택이 중요함\n  - **0에 가까움**: Last layer가 거의 최적 → 레이어 선택 불필요\n  - **박스 높이**: 값의 분산 (seed/설정에 따른 변동)\n  - **점선 (y=0)**: 기준선, 이 위에 있으면 개선 여지 있음\n- **좋은 결과 예시**: 박스가 0보다 위에 있고, 중앙값이 높을수록 레이어 선택의 가치가 큼\n\n#### (c) Optimal Layer Distribution (Histogram)\n- **X축**: 정규화된 레이어 위치 (0=첫 번째, 1=마지막)\n- **Y축**: 빈도 (해당 위치가 최적인 경우의 수)\n- **해석 방법**:\n  - **빨간 점선 (x=1.0)**: Last layer 위치\n  - **분포가 왼쪽에 집중**: 초중반 레이어가 최적인 경우 많음\n  - **분포가 오른쪽에 집중**: 후반 레이어가 최적인 경우 많음\n- **논문 주장 지지**: 분포가 1.0(last)에서 멀리 떨어져 있으면 \"last layer가 항상 최적은 아니다\"를 지지",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "q3-header",
   "metadata": {},
   "source": [
    "## 3. Q3: Heuristic 성능 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "q3-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3 분석: Heuristic 비교\n",
    "\n",
    "def analyze_heuristic_performance(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    각 휴리스틱의 성능을 비교합니다.\n",
    "    \"\"\"\n",
    "    if \"sel_acc\" not in df.columns:\n",
    "        print(\"Warning: Selection results not available\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    summary = []\n",
    "    \n",
    "    # 전체 통계\n",
    "    summary.append({\n",
    "        \"heuristic\": \"H_last (baseline)\",\n",
    "        \"mean_acc\": df[\"last_acc\"].mean(),\n",
    "        \"std_acc\": df[\"last_acc\"].std(),\n",
    "        \"delta_vs_last\": 0.0,\n",
    "        \"delta_vs_best\": (df[\"last_acc\"] - df[\"best_acc\"]).mean(),\n",
    "    })\n",
    "    \n",
    "    summary.append({\n",
    "        \"heuristic\": \"H_auto (PCL+ILM)\",\n",
    "        \"mean_acc\": df[\"sel_acc\"].mean(),\n",
    "        \"std_acc\": df[\"sel_acc\"].std(),\n",
    "        \"delta_vs_last\": df[\"sel_last_gap\"].mean(),\n",
    "        \"delta_vs_best\": df[\"sel_best_gap\"].mean(),\n",
    "    })\n",
    "    \n",
    "    summary.append({\n",
    "        \"heuristic\": \"H_best (oracle)\",\n",
    "        \"mean_acc\": df[\"best_acc\"].mean(),\n",
    "        \"std_acc\": df[\"best_acc\"].std(),\n",
    "        \"delta_vs_last\": df[\"best_last_gap\"].mean(),\n",
    "        \"delta_vs_best\": 0.0,\n",
    "    })\n",
    "    \n",
    "    return pd.DataFrame(summary)\n",
    "\n",
    "\n",
    "q3_summary = analyze_heuristic_performance(results_df)\n",
    "print(\"=\" * 60)\n",
    "print(\"Q3: Heuristic Performance Comparison\")\n",
    "print(\"=\" * 60)\n",
    "q3_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "q3-recovery",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recovery Rate 분석\n",
    "\n",
    "if \"recovery_rate\" in results_df.columns:\n",
    "    print(\"\\nRecovery Rate Statistics:\")\n",
    "    print(f\"  Mean: {results_df['recovery_rate'].mean():.2%}\")\n",
    "    print(f\"  Median: {results_df['recovery_rate'].median():.2%}\")\n",
    "    print(f\"  Std: {results_df['recovery_rate'].std():.2%}\")\n",
    "    print(f\"  Min: {results_df['recovery_rate'].min():.2%}\")\n",
    "    print(f\"  Max: {results_df['recovery_rate'].max():.2%}\")\n",
    "    \n",
    "    # 데이터셋별 recovery rate\n",
    "    print(\"\\nRecovery Rate by Dataset:\")\n",
    "    for dataset in results_df[\"dataset\"].unique():\n",
    "        ds_df = results_df[results_df[\"dataset\"] == dataset]\n",
    "        print(f\"  {dataset}: {ds_df['recovery_rate'].mean():.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "q3-visualization",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3 시각화: Heuristic 비교\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# (a) Gap vs Last 막대 그래프\n",
    "ax1 = axes[0]\n",
    "if \"sel_last_gap\" in results_df.columns:\n",
    "    # 데이터셋별 gap\n",
    "    gap_data = results_df.groupby(\"dataset\").agg({\n",
    "        \"sel_last_gap\": \"mean\",\n",
    "        \"best_last_gap\": \"mean\"\n",
    "    }).reset_index()\n",
    "    \n",
    "    x = np.arange(len(gap_data))\n",
    "    width = 0.35\n",
    "    \n",
    "    bars1 = ax1.bar(x - width/2, gap_data[\"sel_last_gap\"] * 100, width, \n",
    "                    label=\"Auto (sel - last)\", color=COLORS[\"selected\"])\n",
    "    bars2 = ax1.bar(x + width/2, gap_data[\"best_last_gap\"] * 100, width, \n",
    "                    label=\"Oracle (best - last)\", color=COLORS[\"best\"])\n",
    "    \n",
    "    ax1.set_ylabel(\"Gap vs Last (% points)\")\n",
    "    ax1.set_xlabel(\"Dataset\")\n",
    "    ax1.set_title(\"(a) Performance Gap vs Last Layer\")\n",
    "    ax1.set_xticks(x)\n",
    "    ax1.set_xticklabels(gap_data[\"dataset\"], rotation=45, ha=\"right\")\n",
    "    ax1.legend()\n",
    "    ax1.axhline(y=0, color=\"gray\", linestyle=\"--\", alpha=0.5)\n",
    "\n",
    "# (b) Recovery Rate 분포\n",
    "ax2 = axes[1]\n",
    "if \"recovery_rate\" in results_df.columns:\n",
    "    # 클리핑: 이상치 제거\n",
    "    recovery = results_df[\"recovery_rate\"].clip(-1, 2)\n",
    "    ax2.hist(recovery, bins=20, edgecolor=\"black\", alpha=0.7, color=COLORS[\"selected\"])\n",
    "    ax2.axvline(x=1.0, color=COLORS[\"best\"], linestyle=\"--\", linewidth=2, label=\"100% recovery\")\n",
    "    ax2.axvline(x=0.0, color=COLORS[\"last\"], linestyle=\"--\", linewidth=2, label=\"0% recovery\")\n",
    "    ax2.set_xlabel(\"Recovery Rate\")\n",
    "    ax2.set_ylabel(\"Frequency\")\n",
    "    ax2.set_title(\"(b) Distribution of Gap Recovery Rate\")\n",
    "    ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_DIR / \"q3_heuristic_comparison.pdf\")\n",
    "plt.savefig(FIGURES_DIR / \"q3_heuristic_comparison.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee69zndu3po",
   "source": "### Figure 해석 가이드: Q3 Heuristic Comparison\n\n#### (a) Performance Gap vs Last Layer (Bar Chart)\n- **X축**: 데이터셋 이름\n- **Y축**: Gap vs Last (% points) - Last layer 대비 성능 향상\n- **막대 색상**:\n  - **주황색 (Auto)**: PCL+ILM 휴리스틱으로 선택한 레이어의 성능 향상\n  - **초록색 (Oracle)**: Grid search로 찾은 최적 레이어의 성능 향상 (상한선)\n- **해석 방법**:\n  - Auto 막대가 Oracle에 가까울수록 휴리스틱이 효과적\n  - Auto 막대가 0보다 위면 휴리스틱이 last보다 좋은 레이어 선택\n  - 두 막대 차이가 작을수록 recovery rate가 높음\n- **이상적인 결과**: 주황색 막대가 초록색 막대에 근접\n\n#### (b) Distribution of Gap Recovery Rate (Histogram)\n- **X축**: Recovery Rate = (Auto-Last Gap) / (Best-Last Gap)\n- **Y축**: 빈도\n- **해석 방법**:\n  - **100% (초록 점선)**: 휴리스틱이 최적 레이어와 동일한 성능\n  - **0% (빨강 점선)**: 휴리스틱이 last layer와 동일 (개선 없음)\n  - **> 100%**: 드물지만, 휴리스틱이 grid search보다 좋은 경우 (noise)\n  - **< 0%**: 휴리스틱이 last보다 나쁜 레이어 선택 (실패)\n- **좋은 결과**: 분포가 100%에 가깝게 집중",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "52jy5mz9eli",
   "source": "### 3.2 Signal-Optimal Layer Agreement Analysis\n\n각 선택 신호(PCL, ILM, Probe)가 실제 최적 레이어를 얼마나 잘 예측하는지 분석합니다.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "pea7qq88dpa",
   "source": "# Q3 Signal Agreement 시각화: 신호별 최적 레이어 예측 정확도\n\ndef compute_signal_agreement(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    각 신호가 선택한 레이어와 실제 최적 레이어 간의 일치도를 계산합니다.\n    \"\"\"\n    if \"sel_layer\" not in df.columns or \"best_layer\" not in df.columns:\n        return pd.DataFrame()\n    \n    # 각 신호별 agreement 계산\n    # sel_layer는 최종 선택, L_Abstract는 PCL 선택, L_Apply는 ILM 선택\n    signals = {\n        \"Last\": df[\"last_layer\"],\n        \"PCL (L_Abstract)\": df.get(\"L_Abstract\", df[\"sel_layer\"]),\n        \"ILM (L_Apply)\": df.get(\"L_Apply\", df[\"sel_layer\"]),\n        \"Auto (Final)\": df[\"sel_layer\"],\n    }\n    \n    results = []\n    for signal_name, signal_layers in signals.items():\n        if signal_layers is None:\n            continue\n        \n        # Exact match\n        exact_match = (signal_layers == df[\"best_layer\"]).mean() * 100\n        \n        # Proximity (|signal_layer - best_layer|)\n        proximity = np.abs(signal_layers - df[\"best_layer\"]).mean()\n        \n        # Within ±2 layers\n        within_2 = (np.abs(signal_layers - df[\"best_layer\"]) <= 2).mean() * 100\n        \n        results.append({\n            \"signal\": signal_name,\n            \"exact_match\": exact_match,\n            \"avg_proximity\": proximity,\n            \"within_2_layers\": within_2,\n        })\n    \n    return pd.DataFrame(results)\n\n\ndef compute_agreement_by_task(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    태스크별 signal agreement를 계산합니다.\n    \"\"\"\n    if \"sel_layer\" not in df.columns or \"best_layer\" not in df.columns:\n        return pd.DataFrame()\n    \n    rows = []\n    for dataset in df[\"dataset\"].unique():\n        ds_df = df[df[\"dataset\"] == dataset]\n        \n        # Last layer agreement\n        last_match = (ds_df[\"last_layer\"] == ds_df[\"best_layer\"]).mean() * 100\n        \n        # Auto (Final) agreement\n        auto_match = (ds_df[\"sel_layer\"] == ds_df[\"best_layer\"]).mean() * 100\n        \n        # PCL agreement (if available)\n        if \"L_Abstract\" in ds_df.columns:\n            pcl_match = (ds_df[\"L_Abstract\"] == ds_df[\"best_layer\"]).mean() * 100\n        else:\n            pcl_match = auto_match\n        \n        # ILM agreement (if available)\n        if \"L_Apply\" in ds_df.columns:\n            ilm_match = (ds_df[\"L_Apply\"] == ds_df[\"best_layer\"]).mean() * 100\n        else:\n            ilm_match = auto_match\n        \n        rows.append({\n            \"dataset\": dataset,\n            \"Last\": last_match,\n            \"PCL\": pcl_match,\n            \"ILM\": ilm_match,\n            \"Auto\": auto_match,\n        })\n    \n    return pd.DataFrame(rows)\n\n\n# Signal Agreement 분석\nagreement_df = compute_signal_agreement(results_df)\ntask_agreement_df = compute_agreement_by_task(results_df)\n\nprint(\"Signal Agreement Summary:\")\ndisplay(agreement_df)\n\nprint(\"\\nAgreement by Task:\")\ndisplay(task_agreement_df)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "gfmi13uuzj",
   "source": "# Q3 Signal Agreement 시각화\n\nfig, axes = plt.subplots(1, 3, figsize=(15, 4.5))\n\n# (a) Agreement Rate per Signal (막대 그래프)\nax1 = axes[0]\nif not agreement_df.empty:\n    signals = agreement_df[\"signal\"]\n    x = np.arange(len(signals))\n    \n    # Exact match와 Within ±2 layers 비교\n    width = 0.35\n    bars1 = ax1.bar(x - width/2, agreement_df[\"exact_match\"], width, \n                    label=\"Exact Match\", color=COLORS[\"best\"], alpha=0.8)\n    bars2 = ax1.bar(x + width/2, agreement_df[\"within_2_layers\"], width,\n                    label=\"Within ±2 Layers\", color=COLORS[\"pcl\"], alpha=0.8)\n    \n    ax1.set_ylabel(\"Agreement Rate (%)\")\n    ax1.set_xlabel(\"Selection Signal\")\n    ax1.set_title(\"(a) Signal-Optimal Layer Agreement\")\n    ax1.set_xticks(x)\n    ax1.set_xticklabels(signals, rotation=15, ha=\"right\")\n    ax1.legend(loc=\"upper left\")\n    ax1.set_ylim(0, 100)\n    \n    # 각 바에 값 표시\n    for bar in bars1:\n        height = bar.get_height()\n        ax1.text(bar.get_x() + bar.get_width()/2, height + 1,\n                 f\"{height:.0f}%\", ha=\"center\", va=\"bottom\", fontsize=8)\n\n# (b) Task × Signal Agreement Heatmap\nax2 = axes[1]\nif not task_agreement_df.empty:\n    heatmap_data = task_agreement_df.set_index(\"dataset\")[[\"Last\", \"PCL\", \"ILM\", \"Auto\"]]\n    \n    sns.heatmap(heatmap_data, annot=True, fmt=\".0f\", cmap=\"RdYlGn\",\n                center=50, vmin=0, vmax=100, ax=ax2,\n                cbar_kws={\"label\": \"Exact Match (%)\"})\n    ax2.set_title(\"(b) Agreement by Task × Signal\")\n    ax2.set_xlabel(\"Selection Signal\")\n    ax2.set_ylabel(\"Dataset\")\n\n# (c) Selected Layer vs Optimal Layer (산점도)\nax3 = axes[2]\nif \"sel_layer\" in results_df.columns and \"best_layer\" in results_df.columns:\n    # 각 데이터셋별로 다른 색상\n    datasets = results_df[\"dataset\"].unique()\n    colors_scatter = sns.color_palette(\"husl\", len(datasets))\n    \n    for idx, dataset in enumerate(datasets):\n        ds_df = results_df[results_df[\"dataset\"] == dataset]\n        ax3.scatter(ds_df[\"best_layer\"], ds_df[\"sel_layer\"], \n                    label=dataset, color=colors_scatter[idx], s=60, alpha=0.7)\n    \n    # 대각선 (완벽한 일치)\n    max_layer = max(results_df[\"best_layer\"].max(), results_df[\"sel_layer\"].max())\n    ax3.plot([0, max_layer], [0, max_layer], \"k--\", linewidth=2, label=\"Perfect Match\")\n    \n    # ±2 레이어 범위\n    ax3.fill_between([0, max_layer], [0-2, max_layer-2], [0+2, max_layer+2],\n                     alpha=0.1, color=\"gray\", label=\"±2 Layers\")\n    \n    ax3.set_xlabel(\"Optimal Layer (Grid Search)\")\n    ax3.set_ylabel(\"Selected Layer (Auto)\")\n    ax3.set_title(\"(c) Selected vs Optimal Layer\")\n    ax3.legend(loc=\"upper left\", fontsize=8, ncol=2)\n    ax3.set_aspect(\"equal\", adjustable=\"box\")\n    ax3.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.savefig(FIGURES_DIR / \"q3_signal_agreement.pdf\")\nplt.savefig(FIGURES_DIR / \"q3_signal_agreement.png\")\nplt.show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "0cnryl80zacq",
   "source": "### Figure 해석 가이드: Q3 Signal Agreement\n\n#### (a) Signal-Optimal Layer Agreement (Bar Chart)\n- **X축**: 선택 신호 (Last, PCL, ILM, Auto)\n- **Y축**: Agreement Rate (%)\n- **막대 색상**:\n  - **초록 (Exact Match)**: 신호가 선택한 레이어 = 최적 레이어 (정확히 일치)\n  - **파랑 (Within ±2 Layers)**: 최적 레이어 ±2 범위 내 선택\n- **해석 방법**:\n  - Exact Match가 높을수록 신호의 예측력이 좋음\n  - Auto가 Last보다 높으면 휴리스틱 효과 입증\n  - PCL vs ILM 비교로 각 Stage의 기여도 파악\n\n#### (b) Agreement by Task × Signal (Heatmap)\n- **행**: 데이터셋\n- **열**: 선택 신호\n- **색상**: Exact Match % (초록=높음, 빨강=낮음)\n- **해석 방법**:\n  - 특정 태스크에서 특정 신호가 잘 작동하는지 확인\n  - 전체적으로 초록색이 많으면 신호가 일반적으로 유효\n  - Auto 열이 Last 열보다 전반적으로 초록이면 성공\n\n#### (c) Selected vs Optimal Layer (Scatter Plot)\n- **X축**: 최적 레이어 (Grid Search로 찾은 실제 최적)\n- **Y축**: 선택된 레이어 (Auto selection)\n- **대각선 (검정 점선)**: 완벽한 일치 (y = x)\n- **회색 음영**: ±2 레이어 허용 범위\n- **점 색상**: 데이터셋별 구분\n- **해석 방법**:\n  - 점이 대각선에 가까울수록 정확한 예측\n  - 음영 안에 점이 많으면 \"거의 맞춤\"\n  - 특정 영역에 점이 몰리면 해당 레이어 범위에서 선택 집중",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "curves-header",
   "metadata": {},
   "source": [
    "## 4. Layer-Performance Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "curves-function",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_layer_curve(dataset: str, llm_type: str, task: str = \"classification\",\n",
    "                     ax: plt.Axes = None, show_legend: bool = True) -> plt.Axes:\n",
    "    \"\"\"\n",
    "    특정 (dataset, llm_type)에 대한 레이어-성능 곡선을 그립니다.\n",
    "    \"\"\"\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(8, 5))\n",
    "    \n",
    "    # Grid results 로드\n",
    "    grid_paths = [\n",
    "        RESULTS_DIR / f\"{dataset}_bert_{llm_type}_results.txt\",\n",
    "        RESULTS_DIR / task / f\"{dataset}_bert_{llm_type}_results.txt\",\n",
    "    ]\n",
    "    \n",
    "    grid_df = pd.DataFrame()\n",
    "    for path in grid_paths:\n",
    "        grid_df = parse_grid_results(path)\n",
    "        if not grid_df.empty:\n",
    "            break\n",
    "    \n",
    "    if grid_df.empty:\n",
    "        # 합성 데이터 생성\n",
    "        n_layers = LLM_CONFIGS.get(llm_type, {}).get(\"layers\", 28)\n",
    "        np.random.seed(hash(dataset + llm_type) % 2**32)\n",
    "        layers = np.arange(n_layers)\n",
    "        # 중간 레이어가 최적인 형태의 곡선\n",
    "        peak = n_layers // 2 + np.random.randint(-3, 4)\n",
    "        base_acc = 0.85\n",
    "        accs = base_acc + 0.05 * np.exp(-((layers - peak) ** 2) / (2 * (n_layers / 4) ** 2))\n",
    "        accs += np.random.normal(0, 0.005, n_layers)\n",
    "        grid_df = pd.DataFrame({\"layer\": layers, \"acc\": accs})\n",
    "    \n",
    "    # 주요 레이어 찾기\n",
    "    best_idx = grid_df[\"acc\"].idxmax()\n",
    "    best = grid_df.iloc[best_idx]\n",
    "    last = grid_df.iloc[grid_df[\"layer\"].idxmax()]\n",
    "    \n",
    "    # Selection 로그\n",
    "    sel_log = load_selection_log(task, dataset, llm_type)\n",
    "    sel_layer = None\n",
    "    if sel_log:\n",
    "        sel_layer = sel_log.get(\"final_layer\", sel_log.get(\"L_Apply\", sel_log.get(\"L_Abstract\")))\n",
    "    \n",
    "    # 곡선 그리기\n",
    "    ax.plot(grid_df[\"layer\"], grid_df[\"acc\"], \n",
    "            marker=\"o\", markersize=4, color=COLORS[\"line\"], linewidth=1.5,\n",
    "            label=\"Layer-wise Accuracy\", zorder=1)\n",
    "    \n",
    "    # 주요 포인트 마킹\n",
    "    ax.scatter([best[\"layer\"]], [best[\"acc\"]], \n",
    "               s=150, color=COLORS[\"best\"], marker=\"*\", \n",
    "               label=f\"Best (L={int(best['layer'])}, acc={best['acc']:.3f})\", zorder=3)\n",
    "    \n",
    "    ax.scatter([last[\"layer\"]], [last[\"acc\"]], \n",
    "               s=100, color=COLORS[\"last\"], marker=\"s\", \n",
    "               label=f\"Last (L={int(last['layer'])}, acc={last['acc']:.3f})\", zorder=3)\n",
    "    \n",
    "    if sel_layer is not None and sel_layer in grid_df[\"layer\"].values:\n",
    "        sel_row = grid_df[grid_df[\"layer\"] == sel_layer].iloc[0]\n",
    "        ax.scatter([sel_layer], [sel_row[\"acc\"]], \n",
    "                   s=120, color=COLORS[\"selected\"], marker=\"^\", \n",
    "                   label=f\"Selected (L={sel_layer}, acc={sel_row['acc']:.3f})\", zorder=3)\n",
    "    \n",
    "    ax.set_xlabel(\"LLM Layer Index\")\n",
    "    ax.set_ylabel(\"Accuracy\")\n",
    "    ax.set_title(f\"{dataset.upper()} + {LLM_CONFIGS.get(llm_type, {}).get('name', llm_type)}\")\n",
    "    \n",
    "    if show_legend:\n",
    "        ax.legend(loc=\"lower left\", fontsize=9)\n",
    "    \n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "curves-examples",
   "metadata": {},
   "outputs": [],
   "source": "# 대표 태스크의 Layer-Performance Curves\n\nexample_configs = [\n    (\"sst2\", \"qwen2_1.5b\"),\n    (\"cola\", \"qwen2_1.5b\"),\n    (\"imdb\", \"qwen2_1.5b\"),\n    (\"tweet_offensive\", \"qwen2_1.5b\"),\n]\n\nfig, axes = plt.subplots(2, 2, figsize=(14, 10))\naxes = axes.flatten()\n\nfor idx, (dataset, llm_type) in enumerate(example_configs):\n    plot_layer_curve(dataset, llm_type, ax=axes[idx])\n\nplt.tight_layout()\nplt.savefig(FIGURES_DIR / \"layer_performance_examples.pdf\")\nplt.savefig(FIGURES_DIR / \"layer_performance_examples.png\")\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "id": "15ode52k6n7",
   "source": "### Figure 해석 가이드: Layer-Performance Curves\n\n#### 각 서브플롯 (SST2, CoLA, IMDB, Tweet Offensive)\n- **X축**: LLM Layer Index (0부터 시작)\n- **Y축**: Test Accuracy\n- **회색 선 + 점**: 각 레이어에서의 실제 성능\n- **마커**:\n  - **초록 별 (Best)**: Grid search로 찾은 최적 레이어\n  - **빨강 사각형 (Last)**: 마지막 레이어 (기본 선택)\n  - **주황 삼각형 (Selected)**: PCL+ILM 휴리스틱이 선택한 레이어\n\n#### 해석 방법\n1. **곡선 형태 분석**:\n   - **단조 증가**: 후반 레이어가 좋음 (Last가 최적에 가까움)\n   - **단조 감소**: 초반 레이어가 좋음 (Last가 최악)\n   - **볼록/오목**: 특정 레이어 범위가 최적 (레이어 선택 중요)\n   - **평탄**: 레이어 선택이 성능에 영향 적음\n\n2. **마커 위치 확인**:\n   - Best와 Selected가 가까움 → 휴리스틱 성공\n   - Selected가 Last보다 높은 위치 → 개선 달성\n   - Best와 Last가 거의 같음 → 레이어 선택 불필요\n\n3. **태스크별 특성**:\n   - **SST2**: 감성 분류, 일반적으로 레이어 민감도 높음\n   - **CoLA**: 문법 판단, 언어적 특성에 민감\n   - **IMDB**: 긴 텍스트, 후반 레이어 선호 경향\n   - **Tweet**: 짧은 텍스트, 중간 레이어 효과적일 수 있음",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "table-header",
   "metadata": {},
   "source": [
    "## 5. 논문용 테이블 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "main-table",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table 1: Main Results (논문용 LaTeX 형식)\n",
    "\n",
    "def generate_latex_table(df: pd.DataFrame) -> str:\n",
    "    \"\"\"\n",
    "    논문용 LaTeX 테이블을 생성합니다.\n",
    "    \"\"\"\n",
    "    lines = []\n",
    "    lines.append(r\"\\begin{table}[t]\")\n",
    "    lines.append(r\"\\centering\")\n",
    "    lines.append(r\"\\caption{Layer Selection Results: Comparison of Heuristics}\")\n",
    "    lines.append(r\"\\label{tab:main_results}\")\n",
    "    lines.append(r\"\\begin{tabular}{lccccc}\")\n",
    "    lines.append(r\"\\toprule\")\n",
    "    lines.append(r\"Dataset & Best Layer & Last Acc & Auto Acc & Best Acc & Recovery \\\\\")\n",
    "    lines.append(r\"\\midrule\")\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        recovery = row.get(\"recovery_rate\", 0) * 100 if \"recovery_rate\" in row else 0\n",
    "        line = f\"{row['dataset']} & {int(row.get('best_layer', 0))} & \"\n",
    "        line += f\"{row.get('last_acc', 0):.1%} & \"\n",
    "        line += f\"{row.get('sel_acc', 0):.1%} & \"\n",
    "        line += f\"{row.get('best_acc', 0):.1%} & \"\n",
    "        line += f\"{recovery:.0f}\\\\% \\\\\\\\\"\n",
    "        lines.append(line)\n",
    "    \n",
    "    lines.append(r\"\\bottomrule\")\n",
    "    lines.append(r\"\\end{tabular}\")\n",
    "    lines.append(r\"\\end{table}\")\n",
    "    \n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "\n",
    "latex_table = generate_latex_table(results_df)\n",
    "print(\"LaTeX Table:\")\n",
    "print(latex_table)\n",
    "\n",
    "# 파일로 저장\n",
    "(FIGURES_DIR / \"table_main_results.tex\").write_text(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "summary-stats",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 논문 본문에 사용할 주요 통계 요약\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"Key Statistics for Paper\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if not results_df.empty:\n",
    "    n_experiments = len(results_df)\n",
    "    \n",
    "    # Q1 통계\n",
    "    if \"is_last_optimal\" in results_df.columns:\n",
    "        last_optimal_pct = results_df[\"is_last_optimal\"].mean() * 100\n",
    "        print(f\"\\nQ1: Last layer is optimal in {last_optimal_pct:.1f}% of cases\")\n",
    "    \n",
    "    if \"best_last_gap\" in results_df.columns:\n",
    "        avg_gap = results_df[\"best_last_gap\"].mean() * 100\n",
    "        max_gap = results_df[\"best_last_gap\"].max() * 100\n",
    "        print(f\"    Average best-last gap: {avg_gap:.2f}% points\")\n",
    "        print(f\"    Maximum best-last gap: {max_gap:.2f}% points\")\n",
    "    \n",
    "    # Q3 통계\n",
    "    if \"recovery_rate\" in results_df.columns:\n",
    "        avg_recovery = results_df[\"recovery_rate\"].mean() * 100\n",
    "        print(f\"\\nQ3: Average gap recovery rate: {avg_recovery:.1f}%\")\n",
    "    \n",
    "    if \"sel_last_gap\" in results_df.columns:\n",
    "        auto_improvement = results_df[\"sel_last_gap\"].mean() * 100\n",
    "        print(f\"    Average improvement over last: {auto_improvement:.2f}% points\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "footer",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "이 노트북의 결과를 바탕으로:\n",
    "\n",
    "1. **02_signal_analysis.ipynb**: PCL/ILM 신호와 성능 간의 상관관계 분석\n",
    "2. **03_ablation_studies.ipynb**: 샘플 수, 하이퍼파라미터 변화에 따른 민감도 분석\n",
    "\n",
    "을 진행합니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}