{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# 01. Experiment Results Analysis\n",
    "\n",
    "이 노트북은 레이어 선택 실험 결과를 분석하고 시각화합니다.\n",
    "\n",
    "## 목차\n",
    "1. 환경 설정 및 데이터 로딩\n",
    "2. Q1: Last Layer가 최적인가?\n",
    "3. Q3: Heuristic 성능 비교\n",
    "4. Layer-Performance Curves\n",
    "5. 논문용 Figure 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-header",
   "metadata": {},
   "source": [
    "## 1. 환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "# 논문용 스타일 설정\n",
    "plt.rcParams.update({\n",
    "    'font.size': 11,\n",
    "    'axes.labelsize': 12,\n",
    "    'axes.titlesize': 13,\n",
    "    'xtick.labelsize': 10,\n",
    "    'ytick.labelsize': 10,\n",
    "    'legend.fontsize': 10,\n",
    "    'figure.titlesize': 14,\n",
    "    'figure.dpi': 150,\n",
    "    'savefig.dpi': 300,\n",
    "    'savefig.bbox': 'tight',\n",
    "    'font.family': 'sans-serif',\n",
    "})\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# 프로젝트 루트 설정\n",
    "PROJECT_ROOT = Path(\"..\")\n",
    "RESULTS_DIR = PROJECT_ROOT / \"results\"\n",
    "FIGURES_DIR = Path(\"figures\")\n",
    "FIGURES_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"Project root: {PROJECT_ROOT.resolve()}\")\n",
    "print(f\"Results dir: {RESULTS_DIR.resolve()}\")\n",
    "print(f\"Figures dir: {FIGURES_DIR.resolve()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "config-header",
   "metadata": {},
   "source": [
    "### 1.1 실험 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "config",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실험 설정\n",
    "DATASETS = {\n",
    "    \"classification\": [\"sst2\", \"cola\", \"imdb\", \"tweet_offensive\", \"tweet_sentiment_binary\"],\n",
    "    \"entailment\": [\"snli\", \"mnli\"]\n",
    "}\n",
    "\n",
    "LLM_CONFIGS = {\n",
    "    \"qwen2_0.5b\": {\"name\": \"Qwen2-0.5B\", \"layers\": 24},\n",
    "    \"qwen2_1.5b\": {\"name\": \"Qwen2-1.5B\", \"layers\": 28},\n",
    "    \"qwen2_7b\": {\"name\": \"Qwen2-7B\", \"layers\": 32},\n",
    "}\n",
    "\n",
    "SEEDS = [2023, 2024, 2025]\n",
    "\n",
    "# 색상 팔레트\n",
    "COLORS = {\n",
    "    \"best\": \"#2ecc71\",      # 초록\n",
    "    \"last\": \"#e74c3c\",      # 빨강\n",
    "    \"selected\": \"#f39c12\", # 주황\n",
    "    \"pcl\": \"#3498db\",      # 파랑\n",
    "    \"line\": \"#34495e\",      # 회색\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loaders-header",
   "metadata": {},
   "source": [
    "### 1.2 데이터 로딩 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loaders",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_grid_results(path: Path) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Grid search 결과 파일을 파싱합니다.\n",
    "    예상 형식: layer=0 acc=0.85 f1=0.84\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    if not path.exists():\n",
    "        return pd.DataFrame(columns=[\"layer\", \"acc\", \"f1\"])\n",
    "    \n",
    "    for line in path.read_text().splitlines():\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        parts = line.split()\n",
    "        kv = {}\n",
    "        for p in parts:\n",
    "            if \"=\" in p:\n",
    "                k, v = p.split(\"=\", 1)\n",
    "                kv[k] = v\n",
    "        if \"layer\" not in kv or \"acc\" not in kv:\n",
    "            continue\n",
    "        layer = int(kv[\"layer\"])\n",
    "        acc = float(kv[\"acc\"])\n",
    "        f1 = float(kv.get(\"f1\", kv.get(\"macro_f1\", acc)))\n",
    "        rows.append({\"layer\": layer, \"acc\": acc, \"f1\": f1})\n",
    "    \n",
    "    return pd.DataFrame(rows).sort_values(\"layer\").reset_index(drop=True)\n",
    "\n",
    "\n",
    "def load_selection_log(task: str, dataset: str, llm_type: str, seed: int = 2023) -> Optional[Dict]:\n",
    "    \"\"\"\n",
    "    Selection 로그 JSON 파일을 로드합니다.\n",
    "    \"\"\"\n",
    "    # 여러 가능한 경로 시도\n",
    "    possible_paths = [\n",
    "        RESULTS_DIR / \"layer_selection\" / f\"{task}_{dataset}_{llm_type}_seed{seed}.json\",\n",
    "        RESULTS_DIR / \"layer_selection\" / task / dataset / \"bert\" / llm_type / \"selection.json\",\n",
    "        RESULTS_DIR / f\"{task}_{dataset}_{llm_type}_selection.json\",\n",
    "    ]\n",
    "    \n",
    "    for path in possible_paths:\n",
    "        if path.exists():\n",
    "            return json.loads(path.read_text())\n",
    "    return None\n",
    "\n",
    "\n",
    "def get_layer_stats(grid_df: pd.DataFrame, sel_log: Optional[Dict] = None) -> Dict:\n",
    "    \"\"\"\n",
    "    Grid search 결과에서 주요 통계를 계산합니다.\n",
    "    \"\"\"\n",
    "    if grid_df.empty:\n",
    "        return None\n",
    "    \n",
    "    best_idx = grid_df[\"acc\"].idxmax()\n",
    "    best = grid_df.iloc[best_idx]\n",
    "    last = grid_df.iloc[grid_df[\"layer\"].idxmax()]\n",
    "    \n",
    "    stats = {\n",
    "        \"best_layer\": int(best[\"layer\"]),\n",
    "        \"best_acc\": float(best[\"acc\"]),\n",
    "        \"best_f1\": float(best[\"f1\"]),\n",
    "        \"last_layer\": int(last[\"layer\"]),\n",
    "        \"last_acc\": float(last[\"acc\"]),\n",
    "        \"last_f1\": float(last[\"f1\"]),\n",
    "        \"best_last_gap\": float(best[\"acc\"] - last[\"acc\"]),\n",
    "        \"is_last_optimal\": int(best[\"layer\"]) == int(last[\"layer\"]),\n",
    "        \"total_layers\": len(grid_df),\n",
    "        \"min_acc\": float(grid_df[\"acc\"].min()),\n",
    "        \"max_acc\": float(grid_df[\"acc\"].max()),\n",
    "        \"acc_std\": float(grid_df[\"acc\"].std()),\n",
    "    }\n",
    "    \n",
    "    # Sensitivity 계산\n",
    "    stats[\"sensitivity\"] = (stats[\"max_acc\"] - stats[\"min_acc\"]) / max(stats[\"max_acc\"], 1e-8)\n",
    "    \n",
    "    # Selection 로그가 있으면 추가 정보\n",
    "    if sel_log:\n",
    "        sel_layer = sel_log.get(\"final_layer\", sel_log.get(\"L_Apply\", sel_log.get(\"L_Abstract\", -1)))\n",
    "        if sel_layer >= 0 and sel_layer in grid_df[\"layer\"].values:\n",
    "            sel_row = grid_df[grid_df[\"layer\"] == sel_layer].iloc[0]\n",
    "            stats[\"sel_layer\"] = int(sel_layer)\n",
    "            stats[\"sel_acc\"] = float(sel_row[\"acc\"])\n",
    "            stats[\"sel_last_gap\"] = float(sel_row[\"acc\"] - last[\"acc\"])\n",
    "            stats[\"sel_best_gap\"] = float(sel_row[\"acc\"] - best[\"acc\"])\n",
    "            if stats[\"best_last_gap\"] != 0:\n",
    "                stats[\"recovery_rate\"] = stats[\"sel_last_gap\"] / stats[\"best_last_gap\"]\n",
    "            else:\n",
    "                stats[\"recovery_rate\"] = 1.0\n",
    "    \n",
    "    return stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collect-header",
   "metadata": {},
   "source": [
    "### 1.3 전체 결과 수집"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collect-results",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_all_results() -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    모든 실험 결과를 수집하여 DataFrame으로 반환합니다.\n",
    "    \"\"\"\n",
    "    all_results = []\n",
    "    \n",
    "    for task, datasets in DATASETS.items():\n",
    "        for dataset in datasets:\n",
    "            for llm_type, llm_info in LLM_CONFIGS.items():\n",
    "                # Grid results 파일 경로 시도\n",
    "                grid_paths = [\n",
    "                    RESULTS_DIR / f\"{dataset}_bert_{llm_type}_results.txt\",\n",
    "                    RESULTS_DIR / task / f\"{dataset}_bert_{llm_type}_results.txt\",\n",
    "                    PROJECT_ROOT / \"Classification\" / \"results\" / f\"{dataset}_bert_{llm_type}_results.txt\",\n",
    "                ]\n",
    "                \n",
    "                grid_df = pd.DataFrame()\n",
    "                for path in grid_paths:\n",
    "                    grid_df = parse_grid_results(path)\n",
    "                    if not grid_df.empty:\n",
    "                        break\n",
    "                \n",
    "                sel_log = load_selection_log(task, dataset, llm_type)\n",
    "                stats = get_layer_stats(grid_df, sel_log)\n",
    "                \n",
    "                if stats:\n",
    "                    stats[\"task\"] = task\n",
    "                    stats[\"dataset\"] = dataset\n",
    "                    stats[\"llm_type\"] = llm_type\n",
    "                    stats[\"llm_name\"] = llm_info[\"name\"]\n",
    "                    all_results.append(stats)\n",
    "    \n",
    "    if not all_results:\n",
    "        print(\"Warning: No results found. Creating synthetic example data for demonstration.\")\n",
    "        return create_synthetic_data()\n",
    "    \n",
    "    return pd.DataFrame(all_results)\n",
    "\n",
    "\n",
    "def create_synthetic_data() -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    실제 결과가 없을 때 시연용 합성 데이터 생성\n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "    results = []\n",
    "    \n",
    "    for task, datasets in DATASETS.items():\n",
    "        for dataset in datasets:\n",
    "            for llm_type, llm_info in LLM_CONFIGS.items():\n",
    "                n_layers = llm_info[\"layers\"]\n",
    "                \n",
    "                # 기본 성능 (태스크별로 다르게)\n",
    "                base_acc = np.random.uniform(0.80, 0.92)\n",
    "                \n",
    "                # 레이어별 성능 변동 (중간 레이어가 최적인 경향)\n",
    "                best_layer = np.random.randint(n_layers // 3, 2 * n_layers // 3)\n",
    "                best_acc = base_acc + np.random.uniform(0.02, 0.05)\n",
    "                last_acc = base_acc + np.random.uniform(-0.02, 0.02)\n",
    "                \n",
    "                # Selection이 best에 가깝게\n",
    "                sel_layer = best_layer + np.random.randint(-2, 3)\n",
    "                sel_layer = max(0, min(sel_layer, n_layers - 1))\n",
    "                sel_acc = best_acc - np.random.uniform(0, 0.01)\n",
    "                \n",
    "                results.append({\n",
    "                    \"task\": task,\n",
    "                    \"dataset\": dataset,\n",
    "                    \"llm_type\": llm_type,\n",
    "                    \"llm_name\": llm_info[\"name\"],\n",
    "                    \"best_layer\": best_layer,\n",
    "                    \"best_acc\": best_acc,\n",
    "                    \"last_layer\": n_layers - 1,\n",
    "                    \"last_acc\": last_acc,\n",
    "                    \"best_last_gap\": best_acc - last_acc,\n",
    "                    \"is_last_optimal\": False,\n",
    "                    \"sel_layer\": sel_layer,\n",
    "                    \"sel_acc\": sel_acc,\n",
    "                    \"sel_last_gap\": sel_acc - last_acc,\n",
    "                    \"sel_best_gap\": sel_acc - best_acc,\n",
    "                    \"recovery_rate\": (sel_acc - last_acc) / max(best_acc - last_acc, 1e-8),\n",
    "                    \"sensitivity\": np.random.uniform(0.05, 0.15),\n",
    "                    \"total_layers\": n_layers,\n",
    "                })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "# 결과 수집\n",
    "results_df = collect_all_results()\n",
    "print(f\"Collected {len(results_df)} experiment configurations\")\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "q1-header",
   "metadata": {},
   "source": [
    "## 2. Q1: Last Layer가 최적인가?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "q1-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1 분석: 마지막 레이어 최적성\n",
    "\n",
    "def analyze_last_layer_optimality(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    마지막 레이어가 최적인 경우의 비율과 gap 통계를 계산합니다.\n",
    "    \"\"\"\n",
    "    summary = []\n",
    "    \n",
    "    # 전체 통계\n",
    "    total = len(df)\n",
    "    optimal_count = df[\"is_last_optimal\"].sum() if \"is_last_optimal\" in df.columns else 0\n",
    "    \n",
    "    summary.append({\n",
    "        \"group\": \"Overall\",\n",
    "        \"n_experiments\": total,\n",
    "        \"last_optimal_count\": optimal_count,\n",
    "        \"last_optimal_pct\": 100 * optimal_count / max(total, 1),\n",
    "        \"avg_best_last_gap\": df[\"best_last_gap\"].mean() if \"best_last_gap\" in df.columns else 0,\n",
    "        \"std_best_last_gap\": df[\"best_last_gap\"].std() if \"best_last_gap\" in df.columns else 0,\n",
    "        \"max_best_last_gap\": df[\"best_last_gap\"].max() if \"best_last_gap\" in df.columns else 0,\n",
    "    })\n",
    "    \n",
    "    # 태스크별 통계\n",
    "    for task in df[\"task\"].unique():\n",
    "        task_df = df[df[\"task\"] == task]\n",
    "        optimal_count = task_df[\"is_last_optimal\"].sum() if \"is_last_optimal\" in task_df.columns else 0\n",
    "        summary.append({\n",
    "            \"group\": f\"Task: {task}\",\n",
    "            \"n_experiments\": len(task_df),\n",
    "            \"last_optimal_count\": optimal_count,\n",
    "            \"last_optimal_pct\": 100 * optimal_count / max(len(task_df), 1),\n",
    "            \"avg_best_last_gap\": task_df[\"best_last_gap\"].mean() if \"best_last_gap\" in task_df.columns else 0,\n",
    "            \"std_best_last_gap\": task_df[\"best_last_gap\"].std() if \"best_last_gap\" in task_df.columns else 0,\n",
    "            \"max_best_last_gap\": task_df[\"best_last_gap\"].max() if \"best_last_gap\" in task_df.columns else 0,\n",
    "        })\n",
    "    \n",
    "    # 데이터셋별 통계\n",
    "    for dataset in df[\"dataset\"].unique():\n",
    "        ds_df = df[df[\"dataset\"] == dataset]\n",
    "        optimal_count = ds_df[\"is_last_optimal\"].sum() if \"is_last_optimal\" in ds_df.columns else 0\n",
    "        summary.append({\n",
    "            \"group\": f\"Dataset: {dataset}\",\n",
    "            \"n_experiments\": len(ds_df),\n",
    "            \"last_optimal_count\": optimal_count,\n",
    "            \"last_optimal_pct\": 100 * optimal_count / max(len(ds_df), 1),\n",
    "            \"avg_best_last_gap\": ds_df[\"best_last_gap\"].mean() if \"best_last_gap\" in ds_df.columns else 0,\n",
    "            \"std_best_last_gap\": ds_df[\"best_last_gap\"].std() if \"best_last_gap\" in ds_df.columns else 0,\n",
    "            \"max_best_last_gap\": ds_df[\"best_last_gap\"].max() if \"best_last_gap\" in ds_df.columns else 0,\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(summary)\n",
    "\n",
    "\n",
    "q1_summary = analyze_last_layer_optimality(results_df)\n",
    "print(\"=\" * 60)\n",
    "print(\"Q1: Is the Last Layer Optimal?\")\n",
    "print(\"=\" * 60)\n",
    "q1_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "q1-visualization",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1 시각화: Best-Last Gap 분포\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# (a) Best-Last Gap 분포 (박스플롯)\n",
    "ax1 = axes[0]\n",
    "if \"dataset\" in results_df.columns and \"best_last_gap\" in results_df.columns:\n",
    "    order = results_df.groupby(\"dataset\")[\"best_last_gap\"].mean().sort_values(ascending=False).index\n",
    "    sns.boxplot(data=results_df, x=\"dataset\", y=\"best_last_gap\", order=order, ax=ax1, palette=\"Set2\")\n",
    "    ax1.axhline(y=0, color=\"gray\", linestyle=\"--\", alpha=0.5)\n",
    "    ax1.set_xlabel(\"Dataset\")\n",
    "    ax1.set_ylabel(\"Best - Last Gap (Accuracy)\")\n",
    "    ax1.set_title(\"(a) Performance Gap: Best vs Last Layer\")\n",
    "    ax1.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# (b) 최적 레이어 위치 히스토그램\n",
    "ax2 = axes[1]\n",
    "if \"best_layer\" in results_df.columns and \"total_layers\" in results_df.columns:\n",
    "    # 정규화된 레이어 위치 (0-1)\n",
    "    results_df[\"best_layer_norm\"] = results_df[\"best_layer\"] / results_df[\"total_layers\"]\n",
    "    ax2.hist(results_df[\"best_layer_norm\"], bins=10, edgecolor=\"black\", alpha=0.7, color=COLORS[\"best\"])\n",
    "    ax2.axvline(x=1.0, color=COLORS[\"last\"], linestyle=\"--\", linewidth=2, label=\"Last layer\")\n",
    "    ax2.set_xlabel(\"Normalized Layer Position (0=first, 1=last)\")\n",
    "    ax2.set_ylabel(\"Frequency\")\n",
    "    ax2.set_title(\"(b) Distribution of Optimal Layer Positions\")\n",
    "    ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_DIR / \"q1_last_layer_analysis.pdf\")\n",
    "plt.savefig(FIGURES_DIR / \"q1_last_layer_analysis.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "q3-header",
   "metadata": {},
   "source": [
    "## 3. Q3: Heuristic 성능 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "q3-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3 분석: Heuristic 비교\n",
    "\n",
    "def analyze_heuristic_performance(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    각 휴리스틱의 성능을 비교합니다.\n",
    "    \"\"\"\n",
    "    if \"sel_acc\" not in df.columns:\n",
    "        print(\"Warning: Selection results not available\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    summary = []\n",
    "    \n",
    "    # 전체 통계\n",
    "    summary.append({\n",
    "        \"heuristic\": \"H_last (baseline)\",\n",
    "        \"mean_acc\": df[\"last_acc\"].mean(),\n",
    "        \"std_acc\": df[\"last_acc\"].std(),\n",
    "        \"delta_vs_last\": 0.0,\n",
    "        \"delta_vs_best\": (df[\"last_acc\"] - df[\"best_acc\"]).mean(),\n",
    "    })\n",
    "    \n",
    "    summary.append({\n",
    "        \"heuristic\": \"H_auto (PCL+ILM)\",\n",
    "        \"mean_acc\": df[\"sel_acc\"].mean(),\n",
    "        \"std_acc\": df[\"sel_acc\"].std(),\n",
    "        \"delta_vs_last\": df[\"sel_last_gap\"].mean(),\n",
    "        \"delta_vs_best\": df[\"sel_best_gap\"].mean(),\n",
    "    })\n",
    "    \n",
    "    summary.append({\n",
    "        \"heuristic\": \"H_best (oracle)\",\n",
    "        \"mean_acc\": df[\"best_acc\"].mean(),\n",
    "        \"std_acc\": df[\"best_acc\"].std(),\n",
    "        \"delta_vs_last\": df[\"best_last_gap\"].mean(),\n",
    "        \"delta_vs_best\": 0.0,\n",
    "    })\n",
    "    \n",
    "    return pd.DataFrame(summary)\n",
    "\n",
    "\n",
    "q3_summary = analyze_heuristic_performance(results_df)\n",
    "print(\"=\" * 60)\n",
    "print(\"Q3: Heuristic Performance Comparison\")\n",
    "print(\"=\" * 60)\n",
    "q3_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "q3-recovery",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recovery Rate 분석\n",
    "\n",
    "if \"recovery_rate\" in results_df.columns:\n",
    "    print(\"\\nRecovery Rate Statistics:\")\n",
    "    print(f\"  Mean: {results_df['recovery_rate'].mean():.2%}\")\n",
    "    print(f\"  Median: {results_df['recovery_rate'].median():.2%}\")\n",
    "    print(f\"  Std: {results_df['recovery_rate'].std():.2%}\")\n",
    "    print(f\"  Min: {results_df['recovery_rate'].min():.2%}\")\n",
    "    print(f\"  Max: {results_df['recovery_rate'].max():.2%}\")\n",
    "    \n",
    "    # 데이터셋별 recovery rate\n",
    "    print(\"\\nRecovery Rate by Dataset:\")\n",
    "    for dataset in results_df[\"dataset\"].unique():\n",
    "        ds_df = results_df[results_df[\"dataset\"] == dataset]\n",
    "        print(f\"  {dataset}: {ds_df['recovery_rate'].mean():.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "q3-visualization",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3 시각화: Heuristic 비교\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# (a) Gap vs Last 막대 그래프\n",
    "ax1 = axes[0]\n",
    "if \"sel_last_gap\" in results_df.columns:\n",
    "    # 데이터셋별 gap\n",
    "    gap_data = results_df.groupby(\"dataset\").agg({\n",
    "        \"sel_last_gap\": \"mean\",\n",
    "        \"best_last_gap\": \"mean\"\n",
    "    }).reset_index()\n",
    "    \n",
    "    x = np.arange(len(gap_data))\n",
    "    width = 0.35\n",
    "    \n",
    "    bars1 = ax1.bar(x - width/2, gap_data[\"sel_last_gap\"] * 100, width, \n",
    "                    label=\"Auto (sel - last)\", color=COLORS[\"selected\"])\n",
    "    bars2 = ax1.bar(x + width/2, gap_data[\"best_last_gap\"] * 100, width, \n",
    "                    label=\"Oracle (best - last)\", color=COLORS[\"best\"])\n",
    "    \n",
    "    ax1.set_ylabel(\"Gap vs Last (% points)\")\n",
    "    ax1.set_xlabel(\"Dataset\")\n",
    "    ax1.set_title(\"(a) Performance Gap vs Last Layer\")\n",
    "    ax1.set_xticks(x)\n",
    "    ax1.set_xticklabels(gap_data[\"dataset\"], rotation=45, ha=\"right\")\n",
    "    ax1.legend()\n",
    "    ax1.axhline(y=0, color=\"gray\", linestyle=\"--\", alpha=0.5)\n",
    "\n",
    "# (b) Recovery Rate 분포\n",
    "ax2 = axes[1]\n",
    "if \"recovery_rate\" in results_df.columns:\n",
    "    # 클리핑: 이상치 제거\n",
    "    recovery = results_df[\"recovery_rate\"].clip(-1, 2)\n",
    "    ax2.hist(recovery, bins=20, edgecolor=\"black\", alpha=0.7, color=COLORS[\"selected\"])\n",
    "    ax2.axvline(x=1.0, color=COLORS[\"best\"], linestyle=\"--\", linewidth=2, label=\"100% recovery\")\n",
    "    ax2.axvline(x=0.0, color=COLORS[\"last\"], linestyle=\"--\", linewidth=2, label=\"0% recovery\")\n",
    "    ax2.set_xlabel(\"Recovery Rate\")\n",
    "    ax2.set_ylabel(\"Frequency\")\n",
    "    ax2.set_title(\"(b) Distribution of Gap Recovery Rate\")\n",
    "    ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_DIR / \"q3_heuristic_comparison.pdf\")\n",
    "plt.savefig(FIGURES_DIR / \"q3_heuristic_comparison.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "curves-header",
   "metadata": {},
   "source": [
    "## 4. Layer-Performance Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "curves-function",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_layer_curve(dataset: str, llm_type: str, task: str = \"classification\",\n",
    "                     ax: plt.Axes = None, show_legend: bool = True) -> plt.Axes:\n",
    "    \"\"\"\n",
    "    특정 (dataset, llm_type)에 대한 레이어-성능 곡선을 그립니다.\n",
    "    \"\"\"\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(8, 5))\n",
    "    \n",
    "    # Grid results 로드\n",
    "    grid_paths = [\n",
    "        RESULTS_DIR / f\"{dataset}_bert_{llm_type}_results.txt\",\n",
    "        RESULTS_DIR / task / f\"{dataset}_bert_{llm_type}_results.txt\",\n",
    "    ]\n",
    "    \n",
    "    grid_df = pd.DataFrame()\n",
    "    for path in grid_paths:\n",
    "        grid_df = parse_grid_results(path)\n",
    "        if not grid_df.empty:\n",
    "            break\n",
    "    \n",
    "    if grid_df.empty:\n",
    "        # 합성 데이터 생성\n",
    "        n_layers = LLM_CONFIGS.get(llm_type, {}).get(\"layers\", 28)\n",
    "        np.random.seed(hash(dataset + llm_type) % 2**32)\n",
    "        layers = np.arange(n_layers)\n",
    "        # 중간 레이어가 최적인 형태의 곡선\n",
    "        peak = n_layers // 2 + np.random.randint(-3, 4)\n",
    "        base_acc = 0.85\n",
    "        accs = base_acc + 0.05 * np.exp(-((layers - peak) ** 2) / (2 * (n_layers / 4) ** 2))\n",
    "        accs += np.random.normal(0, 0.005, n_layers)\n",
    "        grid_df = pd.DataFrame({\"layer\": layers, \"acc\": accs})\n",
    "    \n",
    "    # 주요 레이어 찾기\n",
    "    best_idx = grid_df[\"acc\"].idxmax()\n",
    "    best = grid_df.iloc[best_idx]\n",
    "    last = grid_df.iloc[grid_df[\"layer\"].idxmax()]\n",
    "    \n",
    "    # Selection 로그\n",
    "    sel_log = load_selection_log(task, dataset, llm_type)\n",
    "    sel_layer = None\n",
    "    if sel_log:\n",
    "        sel_layer = sel_log.get(\"final_layer\", sel_log.get(\"L_Apply\", sel_log.get(\"L_Abstract\")))\n",
    "    \n",
    "    # 곡선 그리기\n",
    "    ax.plot(grid_df[\"layer\"], grid_df[\"acc\"], \n",
    "            marker=\"o\", markersize=4, color=COLORS[\"line\"], linewidth=1.5,\n",
    "            label=\"Layer-wise Accuracy\", zorder=1)\n",
    "    \n",
    "    # 주요 포인트 마킹\n",
    "    ax.scatter([best[\"layer\"]], [best[\"acc\"]], \n",
    "               s=150, color=COLORS[\"best\"], marker=\"*\", \n",
    "               label=f\"Best (L={int(best['layer'])}, acc={best['acc']:.3f})\", zorder=3)\n",
    "    \n",
    "    ax.scatter([last[\"layer\"]], [last[\"acc\"]], \n",
    "               s=100, color=COLORS[\"last\"], marker=\"s\", \n",
    "               label=f\"Last (L={int(last['layer'])}, acc={last['acc']:.3f})\", zorder=3)\n",
    "    \n",
    "    if sel_layer is not None and sel_layer in grid_df[\"layer\"].values:\n",
    "        sel_row = grid_df[grid_df[\"layer\"] == sel_layer].iloc[0]\n",
    "        ax.scatter([sel_layer], [sel_row[\"acc\"]], \n",
    "                   s=120, color=COLORS[\"selected\"], marker=\"^\", \n",
    "                   label=f\"Selected (L={sel_layer}, acc={sel_row['acc']:.3f})\", zorder=3)\n",
    "    \n",
    "    ax.set_xlabel(\"LLM Layer Index\")\n",
    "    ax.set_ylabel(\"Accuracy\")\n",
    "    ax.set_title(f\"{dataset.upper()} + {LLM_CONFIGS.get(llm_type, {}).get('name', llm_type)}\")\n",
    "    \n",
    "    if show_legend:\n",
    "        ax.legend(loc=\"lower left\", fontsize=9)\n",
    "    \n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "curves-examples",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 대표 태스크의 Layer-Performance Curves\n",
    "\n",
    "example_configs = [\n",
    "    (\"sst2\", \"qwen2_1.5b\"),\n",
    "    (\"cola\", \"qwen2_1.5b\"),\n",
    "    (\"imdb\", \"qwen2_1.5b\"),\n",
    "    (\"tweet_offensive\", \"qwen2_1.5b\"),\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, (dataset, llm_type) in enumerate(example_configs):\n",
    "    plot_layer_curve(dataset, llm_type, ax=axes[idx])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_DIR / \"layer_performance_curves.pdf\")\n",
    "plt.savefig(FIGURES_DIR / \"layer_performance_curves.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "table-header",
   "metadata": {},
   "source": [
    "## 5. 논문용 테이블 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "main-table",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table 1: Main Results (논문용 LaTeX 형식)\n",
    "\n",
    "def generate_latex_table(df: pd.DataFrame) -> str:\n",
    "    \"\"\"\n",
    "    논문용 LaTeX 테이블을 생성합니다.\n",
    "    \"\"\"\n",
    "    lines = []\n",
    "    lines.append(r\"\\begin{table}[t]\")\n",
    "    lines.append(r\"\\centering\")\n",
    "    lines.append(r\"\\caption{Layer Selection Results: Comparison of Heuristics}\")\n",
    "    lines.append(r\"\\label{tab:main_results}\")\n",
    "    lines.append(r\"\\begin{tabular}{lccccc}\")\n",
    "    lines.append(r\"\\toprule\")\n",
    "    lines.append(r\"Dataset & Best Layer & Last Acc & Auto Acc & Best Acc & Recovery \\\\\")\n",
    "    lines.append(r\"\\midrule\")\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        recovery = row.get(\"recovery_rate\", 0) * 100 if \"recovery_rate\" in row else 0\n",
    "        line = f\"{row['dataset']} & {int(row.get('best_layer', 0))} & \"\n",
    "        line += f\"{row.get('last_acc', 0):.1%} & \"\n",
    "        line += f\"{row.get('sel_acc', 0):.1%} & \"\n",
    "        line += f\"{row.get('best_acc', 0):.1%} & \"\n",
    "        line += f\"{recovery:.0f}\\\\% \\\\\\\\\"\n",
    "        lines.append(line)\n",
    "    \n",
    "    lines.append(r\"\\bottomrule\")\n",
    "    lines.append(r\"\\end{tabular}\")\n",
    "    lines.append(r\"\\end{table}\")\n",
    "    \n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "\n",
    "latex_table = generate_latex_table(results_df)\n",
    "print(\"LaTeX Table:\")\n",
    "print(latex_table)\n",
    "\n",
    "# 파일로 저장\n",
    "(FIGURES_DIR / \"table_main_results.tex\").write_text(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "summary-stats",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 논문 본문에 사용할 주요 통계 요약\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"Key Statistics for Paper\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if not results_df.empty:\n",
    "    n_experiments = len(results_df)\n",
    "    \n",
    "    # Q1 통계\n",
    "    if \"is_last_optimal\" in results_df.columns:\n",
    "        last_optimal_pct = results_df[\"is_last_optimal\"].mean() * 100\n",
    "        print(f\"\\nQ1: Last layer is optimal in {last_optimal_pct:.1f}% of cases\")\n",
    "    \n",
    "    if \"best_last_gap\" in results_df.columns:\n",
    "        avg_gap = results_df[\"best_last_gap\"].mean() * 100\n",
    "        max_gap = results_df[\"best_last_gap\"].max() * 100\n",
    "        print(f\"    Average best-last gap: {avg_gap:.2f}% points\")\n",
    "        print(f\"    Maximum best-last gap: {max_gap:.2f}% points\")\n",
    "    \n",
    "    # Q3 통계\n",
    "    if \"recovery_rate\" in results_df.columns:\n",
    "        avg_recovery = results_df[\"recovery_rate\"].mean() * 100\n",
    "        print(f\"\\nQ3: Average gap recovery rate: {avg_recovery:.1f}%\")\n",
    "    \n",
    "    if \"sel_last_gap\" in results_df.columns:\n",
    "        auto_improvement = results_df[\"sel_last_gap\"].mean() * 100\n",
    "        print(f\"    Average improvement over last: {auto_improvement:.2f}% points\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "footer",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "이 노트북의 결과를 바탕으로:\n",
    "\n",
    "1. **02_signal_analysis.ipynb**: PCL/ILM 신호와 성능 간의 상관관계 분석\n",
    "2. **03_ablation_studies.ipynb**: 샘플 수, 하이퍼파라미터 변화에 따른 민감도 분석\n",
    "\n",
    "을 진행합니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
